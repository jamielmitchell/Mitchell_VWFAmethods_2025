{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4275bf97-d36c-4980-83f6-d7b3d6298b5f",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af93ee2e-21ac-4e54-9d3d-508da1cf17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import surface\n",
    "import usefulFunctions as uf\n",
    "import os\n",
    "import glob\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7b9e78-fade-4977-a0a7-cec7f7656c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# falg to save csvs\n",
    "save_csv = True\n",
    "\n",
    "# set directories\n",
    "base_dir = f'{os.path.dirname(os.getcwd())}/'\n",
    "surf_dir = f'{base_dir}data/surface_meshes/'\n",
    "label_dir = f'{base_dir}data/labels/native/sepTask/'\n",
    "csv_dir = f'{base_dir}analysis/CSVs/'\n",
    "\n",
    "# define subject list\n",
    "subs = uf.subject_list(surf_dir)\n",
    "#separate sub list into adults and children\n",
    "id_cutoff = 1000 # split between child and adult ID #s\n",
    "child_subs = [sub for sub in subs if int(sub.split('-')[1]) < id_cutoff]\n",
    "adult_subs = [sub for sub in subs if int(sub.split('-')[1]) >= id_cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b7160-e63d-4875-8139-5315509ee36e",
   "metadata": {},
   "source": [
    "# Calculate Dice Similarity Coefficient (DSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e17bd7-0eb6-4150-82ac-00fa80636020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify groups\n",
    "sub_groups = [subs,child_subs,adult_subs]\n",
    "group_names = ['all','children','adults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e18877c-8e0c-4056-8be1-c2361b67768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "mean: 0.46474833093922663\n",
      "sd: 0.2616974784479382\n",
      "se: 0.03127883132316466\n",
      "children\n",
      "mean: 0.42980497694184705\n",
      "sd: 0.26028333768445366\n",
      "se: 0.03447537027679461\n",
      "adults\n",
      "mean: 0.617961498466199\n",
      "sd: 0.2071087552253124\n",
      "se: 0.05744163358172187\n"
     ]
    }
   ],
   "source": [
    "# loop through ROIs to collect DSC\n",
    "\n",
    "for group_indx, group in enumerate(sub_groups):\n",
    "    dice_cos = []\n",
    "    for sub in group:\n",
    "        # grab any surface file for each participant\n",
    "        surf = surface.load_surf_data(f'{base_dir}data/t_maps/native/allData/{sub}/{sub}_T-v-ALL_LH.curv')\n",
    "    \n",
    "        #grab label paths\n",
    "        ob_labels = glob.glob(f'{label_dir}{sub}/{sub}_task-oneback_T-v-ALL_VWFA*_LH.label')\n",
    "        fix_labels = glob.glob(f'{label_dir}{sub}/{sub}_task-fixation_T-v-ALL_VWFA*_LH.label')\n",
    "    \n",
    "        # continue with DSC caluclation on if participant has both labels\n",
    "        if len(ob_labels)>0 and len(fix_labels)>0:\n",
    "    \n",
    "            # load labels\n",
    "            vwfa_ob = uf.read_in_rois(ob_labels)\n",
    "            vwfa_fix = uf.read_in_rois(fix_labels)\n",
    "    \n",
    "            # create surface masks\n",
    "            vwfa_ob_mask = np.zeros(surf.shape)\n",
    "            vwfa_fix_mask = np.zeros(surf.shape)\n",
    "    \n",
    "            #add binary indiciator in any vertext contianing the roi\n",
    "            vwfa_ob_mask[vwfa_ob]=1\n",
    "            vwfa_fix_mask[vwfa_fix]=1\n",
    "    \n",
    "            #calculate DSC\n",
    "            intersection = np.logical_and(vwfa_ob_mask, vwfa_fix_mask)\n",
    "            dice = 2. * intersection.sum() / (vwfa_ob_mask.sum() + vwfa_fix_mask.sum())\n",
    "            dice_cos.append(dice)\n",
    "        \n",
    "    # print results\n",
    "    print(group_names[group_indx])\n",
    "    print(f'mean: {np.mean(dice_cos)}')\n",
    "    print(f'sd: {np.std(dice_cos)}')\n",
    "    print(f'se: {np.std(dice_cos) / np.sqrt(np.size(dice_cos))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c746f-e734-477a-b4fd-3eeaec69c0ef",
   "metadata": {},
   "source": [
    "# Calculate Size Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb5b2c4-66bf-43dc-b89d-67b511e02df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tasks\n",
    "tasks = ['oneback','fixation']\n",
    "\n",
    "# specify groups\n",
    "sub_groups = [child_subs,adult_subs]\n",
    "group_names = ['children','adults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c72ab41-f168-47d6-970a-bdbc3ff399c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list to store data\n",
    "size_data = []\n",
    "\n",
    "# loop through ROIs to collect size\n",
    "for group_indx, group in enumerate(sub_groups):\n",
    "    dice_cos = []\n",
    "    for sub in group:\n",
    "        for task in tasks:\n",
    "        \n",
    "            #grab label paths\n",
    "            labels = glob.glob(f'{label_dir}{sub}/{sub}_task-{task}_T-v-ALL_VWFA*_LH.label')\n",
    "            \n",
    "            # sum vertices for roi size\n",
    "            if len(labels)>0:\n",
    "                roi_size = len(uf.read_in_rois(labels))\n",
    "            # if label doesn't exist then mark as size 0\n",
    "            else:\n",
    "                roi_size = 0\n",
    "    \n",
    "            # append data to list\n",
    "            size_data.append({'sub': sub,\n",
    "                                 'group': group_names[group_indx],\n",
    "                                 'task': task,\n",
    "                                 'roi_size': roi_size,\n",
    "                                 'log_size': np.log10(roi_size+1)\n",
    "                                })\n",
    "\n",
    "# convert list to data frame\n",
    "size_df = pd.DataFrame(size_data)\n",
    "\n",
    "# save df\n",
    "if save_csv:\n",
    "    size_df.to_csv(f'{csv_dir}VWFA_size.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dadf2f2-53c6-407a-82cb-97a56fed03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table\n",
    "df_wide = size_df.pivot_table(index=['sub','group'], columns='task', values=['roi_size','log_size'], fill_value=0)\n",
    "df_wide = df_wide.reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "df_wide.columns = ['_'.join(filter(None, col)).strip() for col in df_wide.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d0d4633-3cdd-4a50-b4b4-73e55a447141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all\n",
      "TtestResult(statistic=2.4164237826290575, pvalue=0.01758438691028531, df=95)\n",
      "ConfidenceInterval(low=0.029178278323204382, high=0.29786966660528447)\n",
      "\n",
      "children\n",
      "TtestResult(statistic=2.3577396314980645, pvalue=0.02079866463464977, df=81)\n",
      "ConfidenceInterval(low=0.028701384095988852, high=0.33901921096160315)\n",
      "\n",
      "adults\n",
      "TtestResult(statistic=0.5607766830293549, pvalue=0.5844860938289966, df=13)\n",
      "ConfidenceInterval(low=-0.12668111815394945, high=0.21550354089769141)\n"
     ]
    }
   ],
   "source": [
    "# specify group_names\n",
    "group_names = ['all','children','adults']\n",
    "\n",
    "# loop through groups to calculate t stats\n",
    "for group in group_names:\n",
    "    if group == 'all':\n",
    "        test_results = ttest_rel(df_wide['log_size_oneback'],df_wide['log_size_fixation'])\n",
    "    else:\n",
    "        test_results = ttest_rel(df_wide.query('group==@group')['log_size_oneback'],df_wide.query('group==@group')['log_size_fixation'])\n",
    "    \n",
    "    # print results\n",
    "    print(f'\\n{group}')\n",
    "    print(test_results)\n",
    "    print(test_results.confidence_interval())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cf73a-0a94-4ded-9508-b0fa703de26b",
   "metadata": {},
   "source": [
    "# Calculate Selectivity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb4370f4-ea47-46a6-93d5-ef1cfd927577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the psc data\n",
    "psc_df = pd.read_csv(f'{csv_dir}sepTaskROIs_sepTaskMaps_meanPSC.csv')\n",
    "\n",
    "#filter fo only categories of interest\n",
    "psc_data = psc_df.query('category==\"T\" or category==\"noText\"')\n",
    "\n",
    "# pivot wider for convience of SI calculation\n",
    "pivoted_df = psc_data.pivot(columns=['category'],values=['mean_psc'],index=['sub','roi','space','roi_task','map_task'])\n",
    "pivoted_df=pivoted_df.reset_index()\n",
    "\n",
    "# reanme columns\n",
    "pivoted_df.columns = ['_'.join(filter(None, col)).strip() for col in pivoted_df.columns]\n",
    "\n",
    "# calcualte SI\n",
    "pivoted_df['SI'] = ((1 + pivoted_df['mean_psc_T']) - (1 + pivoted_df['mean_psc_noText'])) / ((1 + pivoted_df['mean_psc_T']) + (1 + pivoted_df['mean_psc_noText']))\n",
    "\n",
    "#save df\n",
    "if save_csv:\n",
    "    pivoted_df.to_csv(f'{csv_dir}VWFA_SI.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f71f3e-a082-46d8-8978-6aea04bede6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
